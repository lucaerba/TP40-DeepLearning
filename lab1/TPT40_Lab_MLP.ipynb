{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Deep Learning/ Multi Layer Perceptron/ in keras\n",
    "\n",
    "for TPT40, \n",
    "\n",
    "Authors: geoffroy.peeters@telecom-paristech.fr\n",
    "\n",
    "Last update: 2020/11/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "student = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MLP model with 2 output classes (binary classification):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dummy classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "data = datasets.make_classification(n_samples=1000, n_features=20, n_classes=2)\n",
    "x = data[0]\n",
    "y = data[1]\n",
    "\n",
    "# Split into train and test dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "Create a two-layers MLP (1 hidden layer) with \n",
    "- 32 hidden units\n",
    "- the first activation function as Sigmoid \n",
    "- the output activation function as Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n",
    "\n",
    "# --- Display the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss (to minimize) and optimizer (how to update the weights)\n",
    "\n",
    "Configures the model for training: \n",
    "- define an ```optimizer``` (we will use ```sgd``` with a learn_rate (lr) or 0.01), \n",
    "- define the ```loss``` to be minimized (which loss should be used for a binary classification problem ?)\n",
    "- define a list of ```metrics```to be displayed after each epoch (here we will use ```accuracy```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Use \n",
    "- minibatches of size 32 \n",
    "- iterate over 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance of your model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the performance of your model on the test data during training time\n",
    "\n",
    "Reset your model (by running again its definition code) and measure the performance of your model on test data during training time.\n",
    "- How does the loss on the testing data behaves over time ?\n",
    "- When should we stop training the model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "What happens if:\n",
    "- we replace the activation function of the first layer by a ReLu ?\n",
    "- you change the learning_rate to 0.0001, to 0.1 ?\n",
    "- we increase the number of hidden units in the hidden layer ?\n",
    "- we increase the number to two hidden layers ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MLP with 10 output classes (multi-class problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dummy classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "data = datasets.make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=10)\n",
    "x = data[0]\n",
    "y = data[1]\n",
    "\n",
    "# Split into train and test dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "Create a two-layers MLP (1 hidden layer) with \n",
    "- 32 hidden units\n",
    "- the first activation function as ReLu \n",
    "- which output activation should we use for multi-class classification ?\n",
    "- the network should have has many outputs as classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss (to minimize) and optimizer (how to update the weights)\n",
    "\n",
    "Configures the model for training: \n",
    "- define an ```optimizer``` (we will use ```sgd``` with a learn_rate (lr) or 0.01), \n",
    "- define the ```loss``` to be minimized (which loss should be used for a binary classification problem ?)\n",
    "- define a list of ```metrics```to be displayed after each epoch (here we will use ```accuracy```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting ground-truth output values to one-hot-vector\n",
    "\n",
    "So far $y^{(i)}$ represent labels (values between 0 and 9); we need to convert it to one-hot-vector encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    y_train_ov = ...\n",
    "    y_test_ov = ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Use \n",
    "- batches of size 32 \n",
    "- iterate for 200 epochs.\n",
    "\n",
    "Also evaluate the performances of the model and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On real data: reuters\n",
    "\n",
    "## Reuters newswire topics classification\n",
    "\n",
    "Reuters dataset is made of 11,228 newswires from Reuters, labeled over 46 topics. \n",
    "Each wire is encoded as a sequence of word indexes (same conventions).\n",
    "\n",
    "In this dataset, both inputs and outputs need to be encoded using one-hot-encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset and convert it to an \"easy to process\" format\n",
    "\n",
    "The code is provided but we ask you to explain it.\n",
    "\n",
    "### Question\n",
    "\n",
    "Explain what are the steps for converting the ```reuters.load_data``` to the correct format ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains and evaluate a simple MLP on the Reuters newswire topic classification task.'''\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 1000\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('x_train type: {}'.format(type(x_train)))\n",
    "print(\"x_train[0] type: {}\".format(type(x_train[0])))\n",
    "print('y_train type: {}'.format(type(y_train)))\n",
    "\n",
    "print('x_train shape: {}'.format(x_train.shape))\n",
    "print('x_test shape: {}'.format(x_test.shape))\n",
    "\n",
    "print(\"x_train[0]: {}\".format(x_train[0]))\n",
    "print(\"y_train[0]: {}\".format(y_train[0]))\n",
    "\n",
    "\n",
    "word_index = reuters.get_word_index()\n",
    "#print(word_index)\n",
    "[word for word, index in word_index.items() if index == 2]\n",
    "index_word = {value: key for key, value in word_index.items()}\n",
    "\"-\".join([index_word[x] for x in x_train[0]])\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(\"x_train[0]: {}\".format(x_train[0]))\n",
    "print(\"y_train[0]: {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting ground-truth output values to one-hot-vector\n",
    "\n",
    "So far  y(i) represent labels (values between 0 and 9); we need to convert it to one-hot-vector encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "\n",
    "if student:\n",
    "    # START CODE HERE\n",
    "    y_train_ov = ...\n",
    "    y_test_ov = ...\n",
    "    # END CODE HERE\n",
    "\n",
    "print('y_train_ov shape:', y_train.shape)\n",
    "print('y_test_ov shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the whole system: model + compile + fit\n",
    "\n",
    "We will use \n",
    "- a 3 layers Neural Network (2 hidden layers)\n",
    "- with 512 hidden units each and Relu activation\n",
    "- what is the number of output classes ?\n",
    "- what should be the acitvation function of the output class ?\n",
    "\n",
    "We will use\n",
    "- as ```optimizer``` a ```sgd``` with a learn_rate of 0.01, \n",
    "- which loss should be used for a multi-class classification problem ?\n",
    "- as ```metrics```to be displayed after each epoch the ```accuracy```\n",
    "\n",
    "We will use\n",
    "- batch_size of 32\n",
    "- 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if student:\n",
    "    # START CODE HERE\n",
    "    ...\n",
    "    # END CODE HERE\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What are the performances on the test data ? Loss and Accuracy ?\n",
    "\n",
    "### Question\n",
    "\n",
    "Write the same model using Keras functional API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
