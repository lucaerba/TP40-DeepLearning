{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "BinaryClassifier_solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpnML8RSbUZj"
      },
      "source": [
        "#Importing keras and the required libraies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGxc8eGVbElR"
      },
      "source": [
        "# Numpy is Python standard library for tensor manipulation\n",
        "import numpy as np\n",
        "# Seeding numpy random number generator for results reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Matplotlib will be used for all plotting tasks\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Importing the Keras 2.x main module relying on tensorflow 2.x backend\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "print(\"Using tensorflow version \" + str(tf.__version__))\n",
        "print(\"Using keras version \" + str(keras.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3h9w63cDYJ"
      },
      "source": [
        "# Generating a dataset of non linearly separable points in a bidimensional feature space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Z39RZyR5bElb"
      },
      "source": [
        "# Sklearn will be used to generate our synthetic dataset\n",
        "from sklearn import datasets\n",
        "X, y = datasets.make_moons(n_samples=1000, noise=0.1, random_state=0)\n",
        "colors = ['steelblue' if label == 1 else 'darkred' for label in y]\n",
        "plt.scatter(X[:,0], X[:,1], color=colors)\n",
        "y.shape, X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tw6OqWtcoH1"
      },
      "source": [
        "#Defining the neural network architecture (i.e., the network model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkiAIwq4bEld"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# Define our model object\n",
        "model = Sequential()\n",
        "\n",
        "# One layer network\n",
        "#model.add(Dense(input_shape=(2,), activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "# Two layers network\n",
        "model.add(Dense(input_shape=(2,), activation=\"sigmoid\", units=5, kernel_initializer=\"glorot_uniform\"))\n",
        "model.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "# Three layers network\n",
        "#model.add(Dense(input_shape=(2,), activation=\"sigmoid\", units=5, kernel_initializer=\"glorot_uniform\"))\n",
        "#model.add(Dense(activation=\"sigmoid\", units=5, kernel_initializer=\"glorot_uniform\"))\n",
        "#model.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hMVTfRrctKR"
      },
      "source": [
        "Instantiating a SGD optimizer and compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr00IPHnbElf"
      },
      "source": [
        "# Optimizer modules provide a number of optimization algorithms for updating\n",
        "# a netwok parameters accoridng to the computed error gradients\n",
        "\n",
        "# Defining our SGD optimizer\n",
        "sgd = optimizer=tf.keras.optimizers.SGD(lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVRLXSqpbElg"
      },
      "source": [
        "# Compiling a model in Keras amounts to associating th eoptimizer to a model with an appropriate loss function\n",
        "model.compile(optimizer=sgd, loss='mse', metrics = ['accuracy'])\n",
        "\n",
        "# Let us have a look at the model topology\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6c16yORS2tV"
      },
      "source": [
        "# Training the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-HJzOyibEli"
      },
      "source": [
        "# This is where the actual training-testing happens\n",
        "# Number of epochs we want to train\n",
        "epochs = 10\n",
        "# We restrict the training to 10k images to cut time\n",
        "n_train_samples = 1000\n",
        "# This is where the actual training happens (no test dataset is considered in this case)\n",
        "history = model.fit(X[:n_train_samples], y[:n_train_samples], verbose=1, epochs=epochs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53fdIk1IdYSN"
      },
      "source": [
        "# Evaluating the trained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "enu4xmmObElk"
      },
      "source": [
        "# We now want to plot the train and validation loss functions and accuracy curves\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDRj7Ti9dleb"
      },
      "source": [
        "# Visualizing the decision plane learned by the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6G0b2twbEll"
      },
      "source": [
        "# This function plots the output of the output neuron as a function of the network inputs \n",
        "def plot_decision_boundary(X, y, model, steps=1000, cmap='Paired'):\n",
        "    \"\"\"\n",
        "    Function to plot the decision boundary and data points of a model.\n",
        "    Data points are colored based on their actual label.\n",
        "    \"\"\"\n",
        "    cmap = plt.get_cmap(cmap)\n",
        "    \n",
        "    # Define region of interest by data limits\n",
        "    xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "    ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "    steps = 1000\n",
        "    x_span = np.linspace(xmin, xmax, steps)\n",
        "    y_span = np.linspace(ymin, ymax, steps)\n",
        "    xx, yy = np.meshgrid(x_span, y_span)\n",
        "\n",
        "    # Make predictions across region of interest\n",
        "    labels = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Plot decision boundary in region of interest\n",
        "    z = labels.reshape(xx.shape)\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
        "\n",
        "    # Get predicted labels on training data and plot\n",
        "    train_labels = model.predict(X)\n",
        "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n",
        "    \n",
        "    return fig, ax\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU8mdRV9bElo"
      },
      "source": [
        "plot_decision_boundary(X, y, model, cmap='RdBu')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}